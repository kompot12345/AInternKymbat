# -*- coding: utf-8 -*-
"""AInternKymbat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vKnAk9GYOcmUpJ4DiuVM0rv2XODZzuDI
"""

import os
import sqlite3
import PyPDF2
from langchain_openai import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

# Set up OpenAI API key
OPENAI_API_KEY = ""

# Initialize OpenAI model
llm = ChatOpenAI(model="gpt-4o", temperature=0, api_key=OPENAI_API_KEY)

# Database setup
DB_PATH = "business_data.db"

# Delete existing database if needed
if os.path.exists(DB_PATH):
    os.remove(DB_PATH)
    print("Existing database file deleted.")

# Function to extract text from a PDF file
def extract_text_from_pdf(pdf_path):
    reader = PyPDF2.PdfReader(pdf_path)
    text = ""
    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"
    return text.strip()

# Function to store extracted text in SQLite database with Full-Text Search (FTS5)
def store_data_in_db(pdf_text):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # Create a full-text search table (FTS5)
    cursor.execute("DROP TABLE IF EXISTS product_info")
    cursor.execute('''
        CREATE VIRTUAL TABLE product_info USING fts5(content)
    ''')

    # Insert text into the table
    cursor.execute("INSERT INTO product_info (content) VALUES (?)", (pdf_text,))

    conn.commit()
    conn.close()

# Load and process PDF
pdf_path = "business_data.pdf"
if os.path.exists(pdf_path):
    pdf_text = extract_text_from_pdf(pdf_path)
    store_data_in_db(pdf_text)
    print("PDF data successfully stored in SQLite database!")
else:
    print("PDF file not found! Please upload a valid PDF file.")

# Function to fetch the most relevant content from the database using FTS5 search
def fetch_answer_from_db(question):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # Escape special characters in the question to avoid syntax errors
    question = question.replace('"', '""')  # Replace double quotes with two double quotes
    question = question.replace("'", "''")  # Replace single quotes with two single quotes

    # Perform a full-text search for the question, use fts5 function
    cursor.execute(f"SELECT content FROM product_info WHERE content MATCH '\"{question}\"' LIMIT 1")

    result = cursor.fetchone()

    conn.close()
    return result[0] if result else None

# Vector search setup
def setup_vector_search():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute("SELECT content FROM product_info")
    documents = [row[0] for row in cursor.fetchall()]

    conn.close()

    # Improved chunking for better search
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    docs = text_splitter.split_text(" ".join(documents))

    embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
    vector_store = FAISS.from_texts(docs, embeddings)

    return vector_store

vector_store = setup_vector_search()

# AI-powered question answering
def answer_customer_question(question):
    # Step 1: Fetch from SQL database (priority)
    context = fetch_answer_from_db(question)

    if not context:
        # Step 2: Use FAISS vector search if SQL search fails
        retriever = vector_store.as_retriever(search_kwargs={"k": 3})  # Get top-3 results
        results = retriever.invoke(question)
        context = " ".join([doc.page_content for doc in results]) if results else None

    if not context:
        return "Sorry, I couldn't find an answer in the document."

    # Step 3: Use OpenAI to generate a structured response
    prompt = f"""
    You are an AI assistant answering customer questions about a product based only on the provided business document.

    **Customer Question:** {question}

    **Business Document Excerpt:** {context}

    Please answer concisely and accurately using only the provided document.
    """
    response = llm.invoke(prompt)

    return response.content.strip()  # Return only clean text

# Function to simulate customer query handling
def handle_customer_query(message):
    print(f"Customer: {message}")
    bot_response = answer_customer_question(message)
    print(f"Bot: {bot_response}\n")
    return bot_response

# Simulating customer questions
if __name__ == "__main__":
    while True:
        user_input = input("Ask a question about the product (or type 'exit' to stop): ")
        if user_input.lower() == "exit":
            break
        response = handle_customer_query(user_input)

!pip install -U langchain-community

! pip install langchain-openai langchain faiss-cpu openai pypdf requests python-dotenv

import sqlite3
print(sqlite3.sqlite_version)